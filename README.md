# iris-mlops-end-to-end

Projeto de ponta a ponta para classificaÃ§Ã£o com foco em **MLOps** usando o dataset Breast Cancer do scikit-learn, pipeline de treinamento em Python e aplicaÃ§Ã£o web com Flask para inferÃªncia via upload de CSV.

## ğŸ“Œ VisÃ£o geral

Este repositÃ³rio implementa um fluxo simples de ML com as etapas:

1. **Coleta de dados** (`src/data_loading/load_data.py`)
2. **PrÃ©-processamento** (`src/data_preprocessing/preprocess_data.py`)
3. **Engenharia de atributos** (`src/feature_engineering/engineer_features.py`)
4. **Treinamento do modelo** (`src/model_training/train_model.py`)
5. **AvaliaÃ§Ã£o** (`src/model_evaluation/evaluate_model.py`)
6. **Serving** com Flask (`app/main.py`)

A aplicaÃ§Ã£o recebe um arquivo CSV com as features esperadas e retorna as prediÃ§Ãµes do modelo treinado.

---

## ğŸ§± Estrutura do projeto

```bash
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # API/UI Flask para inferÃªncia
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html             # Interface de upload do CSV
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loading/
â”‚   â”‚   â””â”€â”€ load_data.py           # Carrega dataset e salva em data/raw
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess_data.py     # Split + imputaÃ§Ã£o
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”‚   â””â”€â”€ engineer_features.py   # Escalonamento de features
â”‚   â”œâ”€â”€ model_training/
â”‚   â”‚   â””â”€â”€ train_model.py         # Treinamento Keras + artefatos
â”‚   â””â”€â”€ model_evaluation/
â”‚       â””â”€â”€ evaluate_model.py      # MÃ©tricas no conjunto de teste
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ preprocessed/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ artifacts/                     # Imputer, scaler e encoder
â”œâ”€â”€ models/                        # Modelo treinado (.keras)
â”œâ”€â”€ metrics/                       # MÃ©tricas de treino/avaliaÃ§Ã£o
â”œâ”€â”€ params.yaml                    # HiperparÃ¢metros e configs do pipeline
â”œâ”€â”€ pyproject.toml                 # DependÃªncias do projeto
â””â”€â”€ Dockerfile                     # Container para serving com Gunicorn
```

---

## âœ… PrÃ©-requisitos

- Python **3.12+**
- `pip`

> ObservaÃ§Ã£o: o treinamento usa TensorFlow/Keras, entÃ£o Ã© necessÃ¡rio ter essa dependÃªncia instalada no ambiente (ela nÃ£o estÃ¡ listada hoje no `pyproject.toml`).

---

## âš™ï¸ ConfiguraÃ§Ã£o do ambiente

Na raiz do projeto:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
pip install --upgrade pip
pip install -e .
```

Se necessÃ¡rio, instale tambÃ©m:

```bash
pip install tensorflow joblib
```

---

## ğŸ§ª Como executar o pipeline manualmente

Antes de treinar, preencha os valores de `params.yaml` (atualmente estÃ£o vazios), por exemplo:

```yaml
train:
  learning_rate: 0.001
  hidden_layer_1_neurons: 64
  hidden_layer_2_neurons: 32
  dropout_rate: 0.2
  epochs: 50
  batch_size: 32
  random_seed: 42

preprocess_data:
  test_size: 0.2
  random_seed: 42
```

Execute as etapas na sequÃªncia:

```bash
python src/data_loading/load_data.py
python src/data_preprocessing/preprocess_data.py
python src/feature_engineering/engineer_features.py
python src/model_training/train_model.py
python src/model_evaluation/evaluate_model.py
```

SaÃ­das esperadas:

- `data/raw/raw.csv`
- `data/preprocessed/*.csv`
- `data/processed/*.csv`
- `artifacts/*.joblib`
- `models/model.keras`
- `metrics/training.json`
- `metrics/evaluation.json`

---

## ğŸš€ Executar a aplicaÃ§Ã£o Flask

ApÃ³s gerar os artefatos de treinamento:

```bash
python app/main.py
```

A aplicaÃ§Ã£o ficarÃ¡ disponÃ­vel em:

- `http://localhost:5001`

Fluxo de uso:

1. Acesse a pÃ¡gina inicial.
2. FaÃ§a upload de um CSV com as colunas esperadas do dataset.
3. Visualize as prediÃ§Ãµes na interface.

---

## ğŸ³ Executar com Docker

Build da imagem:

```bash
docker build -t iris-mlops-e2e .
```

Run do container:

```bash
docker run --rm -p 5001:5001 iris-mlops-e2e
```

Servidor disponÃ­vel em `http://localhost:5001`.

---

## ğŸ” PossÃ­veis melhorias

- Incluir `tensorflow` e `joblib` no `pyproject.toml`.
- Automatizar o pipeline com um orquestrador (ex.: Makefile, DVC, Airflow, Prefect).
- Adicionar testes unitÃ¡rios e de integraÃ§Ã£o.
- Melhorar versionamento e rastreabilidade de modelos/experimentos.

---

## ğŸ“„ LicenÃ§a

Defina aqui a licenÃ§a do projeto (ex.: MIT, Apache-2.0).
